Tại sao mỗi người đi vay với những điều kiện khác nhau (thu nhập, nhà cửa, mục đích đi vay, số năm làm việc, ...

- 7 categorical
	'Loan_Amount_Requested',: So luong tien muon vay
 	'Length_Employed',: Thoi gian lam viec hien tai lam viec cua nguoi di vay
	 'Home_Owner',: Nha o hien tai cua nguoi di vay
	 'Income_Verified',: Thu nhap da duoc xac thuc hay chua
	 'Purpose_Of_Loan',: Muc dich di vay
	 'Gender': Gioi tinh
- 7 numerical
	'Annual_Income': Thu nhap hang nam
	'Debt_To_Income',: So tien no / muc thu nhap
 	'Inquiries_Last_6Mo',: So luong thac mac cua chu no trong 6 thang qua
 	'Months_Since_Deliquency',: So thang ke tu 
 	'Number_Open_Accounts',
 	'Total_Accounts',
 	'Interest_Rate'

- Purpose of the loan:
['car' 'credit_card' 'debt_consolidation' 'educational' 'home_improvement'
   'house' 'major_purchase' 'medical' 'move' 'other' 'renewable_energy'
   'small_business' 'holiday' 'wedding']
	+ Mục đích vay dành cho tài sản (mục đích đẻ ra tiền)
		* 'educational', 'home_improvement', 'house' 
	+ Mục đích vay dành cho tiêu sản (mục đích ăn chơi và có thể lấy thêm thu nhập của bạn do chi phí dịch vụ)
		* 'car', 'credit_card', 


- Missing Value
	+ Length_Employed
	+ Home_Owner
	+ Annual_Income
	+ Months_Since_Deliquency

	- Thay missing và value < 0 trong Annual_Income bằng mean
	- Binning Annual_Income 
	pd.cut(df['Annual_Income'],bins=[-np.inf,50000,100000,500000,np.inf], labels=[1,2,3,4]).astype(int)
	- Dept = Annual_Income * Debt_To_Income (cùng đơn vị nha) 
	+ Kiểm tra bằng sns.distplot(df['Debt'])
	- Tại sao nên dùng log     df['LogDebt'] = df['Debt'].apply(lambda x: np.log(x) if x!= 0 else 0)  
	+ Kiểm tra bằng sns.distplot(train_data['LogDebt'])

	- #Credit Rating
	df['Credit_rating'] = df['Debt']*0.4 + df['Annual_Income']*0.45 + df['Purpose_Of_Loan']*0.1
	

- Convert catogorical to numerical
	+ Purpose_Of_Loan
	+ Income_Verified
	+ Home_Owner 
	+ Length_Employed
	+ Loan_Amount_Requested


- 


- Outlier 




- MODEL TRAINING
+ BASE LINE
	* Decision tree accuracy is:
	* RandomForestClassifier accuracy is:

+ DROP GENDER
	* Decision tree accuracy is: 42.78%
	* RandomForestClassifier accuracy is: 51.63%

+ outlier better
	* Decision tree accuracy is:
	* RandomForestClassifier accuracy is:
+ 
	* Decision tree accuracy is: 42.79%
	* RandomForestClassifier accuracy is:51.65%
+ 

name	accuracy score	recall score
0	GaussianNB	0.489887	0.489887
1	RandomForest	0.516077	0.516077
2	KNN	0.421378	0.421378

	Name	Accuracy score	Recall score
0	GaussianNB	49.76%	49.76%
1	RandomForest	51.36%	51.36%
2	KNN	44.82%	44.82%

Name	Accuracy score
0	GaussianNB	49.76%
1	RandomForest	51.49%
2	KNN	44.29%

Name	Accuracy score
0	Random Forest	51.65%
1	Neural Networks (Multi-Layer Perceptron)	52.71%
2	Gradient Boosting Classifier	53.62%

Name	Accuracy score
0	Random Forest	51.64%
1	Neural Networks (Multi-Layer Perceptron)	53.02%
2	Gradient Boosting Classifier	53.66%

	* Decision tree accuracy is:
	* RandomForestClassifier accuracy is:
+ 
	* Decision tree accuracy is:
	* RandomForestClassifier accuracy is:
+ 
	* Decision tree accuracy is:
	* RandomForestClassifier accuracy is:
+ 
	* Decision tree accuracy is:
	* RandomForestClassifier accuracy is:
+ 
	* Decision tree accuracy is:
	* RandomForestClassifier accuracy is:

Name	Accuracy score
0	Gaussian Naive Bayes	50.17%
1	Random Forest	51.91%
2	K-Nearest Neighbors Classifier	44.87%
3	Neural Networks	53.14%
4	Gradient Boosting Classifier	53.66%
5	Support Vector Machines (SVM) Classifier	52.3%

Name	Accuracy score
0	Gaussian Naive Bayes	50.14%
1	Random Forest	51.89%
2	K-Nearest Neighbors Classifier	44.89%
3	Neural Networks	53.09%
4	Gradient Boosting Classifier	53.44%
5	Support Vector Machines (SVM) Classifier	52.14%